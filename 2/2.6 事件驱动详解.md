## 2.6 事件驱动详解

由于Nginx采用的是多进程的模式，会存在惊群问题。在Nginx上表现为：Nginx的所有工作进程都要监听socket，当有一个客户端要连到Nginx服务器上，会造成资源的竞争从而造成系统性能下降。

我们之前说过，Nginx事件驱动的核心是ngx_process_events_and_timers函数。接下来我们详细看以下该函数，看其如何处理负载均衡、惊群处理和事件分发。具体代码如下所示：

```c
void ngx_process_events_and_timers(ngx_cycle_t *cycle) {
    ngx_uint_t flags;
    ngx_msec_t timer, delta;  
  
    if (ngx_timer_resolution) {  
        timer = NGX_TIMER_INFINITE;  
        flags = 0;  
    } else {  
        timer = ngx_event_find_timer();  
        flags = NGX_UPDATE_TIME;
        ...
    } 
     
    //ngx_use_accept_mutex变量代表是否使用accept锁，默认true
    if (ngx_use_accept_mutex) {  
        //负载均衡处理 
        if (ngx_accept_disabled > 0) {  
            ngx_accept_disabled--;  
        } else {  
            //通过竞争锁解决惊群问题  
            if (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) {  
                return;  
            }  
  
            //成功获取到锁  
            if (ngx_accept_mutex_held) {  
                //增加标记NGX_POST_EVENTS，告诉ngx_process_events函数将相关事件分到ngx_posted_accept_events和ngx_posted_events队列。 
                flags |= NGX_POST_EVENTS;
            } else {
                //获取锁失败
                if (timer == NGX_TIMER_INFINITE || timer > ngx_accept_mutex_delay) {  
                    timer = ngx_accept_mutex_delay;  
                }  
            }  
        }  
    }  
    
    //事件处理函数，并计算执行时消耗的时间    
    delta = ngx_current_msec;
    (void) ngx_process_events(cycle, timer, flags);  
    delta = ngx_current_msec - delta;  
  
    //处理ngx_posted_accept_events队列中保存的accept事件 
    ngx_event_process_posted(cycle, &ngx_posted_accept_events);  
    
    //如果拿到锁，处理完accept事件后，则释放锁  
    if (ngx_accept_mutex_held) {  
        ngx_shmtx_unlock(&ngx_accept_mutex);  
    }  
  
    if (delta) {  
        ngx_event_expire_timers();  
    }  
    
    //处理ngx_posted_events队列中保存的普通事件 
    ngx_event_process_posted(cycle, &ngx_posted_events);  
}
```
该函数虽然不长，却有很多比较关键的地方，接下来我们会一一详述：

首先我们看一下Nginx如何处理负载均衡：
* 当事件配置初始化的时候，会设置一个全局变量ngx_accept_disabled = ngx_cycle->connection_n / 8 - ngx_cycle->free_connection_n； 
* 当ngx_accept_disabled为正数时，就不再处理新的连接accept事件，同时将其减1，直到ngx_accept_disabled降到总连接的7/8以下时，才会调用ngx_trylock_accept_mutex尝试处理新连接事件。

接下来我们看一下惊群处理：
* 首先通过ngx_trylock_accept_mutex争抢ngx_accept_mutex，成功获取锁时，才可以处理accept事件。
* 获取锁失败时，接下来调用事件处理函数ngx_process_events时只处理已有连接上的事件，而且是直接调用ev->handler回调函数处理该事件。
* 成功获取锁时，调用ngx_process_events函数时就既需要处理已有连接上的事件，还需要处理新连接上的事件。此时为了防止长时间占用ngx_accept_mutex，ngx_process_events函数在处理事件时会首先将所有事件先放入队列中（NGX_POST_EVENTS标志位），accept事件放入到ngx_posted_accept_events，普通事件放入到ngx_posted_events。接下来会优先处理ngx_posted_accept_events队列中的事件，处理完后立即释放ngx_accept_mutex锁。然后再处理ngx_posted_events队列中的事件。

我们详细看一下这个过程：

```c
ngx_int_t ngx_trylock_accept_mutex(ngx_cycle_t *cycle) {
    //成功获取锁
    if (ngx_shmtx_trylock(&ngx_accept_mutex)) {
        //判断是否已经拿到锁
        if (ngx_accept_mutex_held && ngx_accept_events == 0) {
            return NGX_OK;
        }  
  
        //调用ngx_enable_accept_events函数，将监听套接字的读事件添加到当前使用的事件驱动模块中
        if (ngx_enable_accept_events(cycle) == NGX_ERROR) {  
            ngx_shmtx_unlock(&ngx_accept_mutex);  
            return NGX_ERROR;  
        }  
  
        ngx_accept_events = 0;  
        ngx_accept_mutex_held = 1;  
  
        return NGX_OK;  
    }  
  
    if (ngx_accept_mutex_held) {  
        //没有拿到锁，调用ngx_disable_accept_events函数，将监听套接字的读事件从当前事件模块中删除
        if (ngx_disable_accept_events(cycle, 0) == NGX_ERROR) {  
            return NGX_ERROR;  
        }  
  
        ngx_accept_mutex_held = 0;  
    }  
  
    return NGX_OK;  
}

static ngx_int_t ngx_enable_accept_events(ngx_cycle_t *cycle) {
    ngx_uint_t i;
    ngx_listening_t *ls;
    ngx_connection_t *c;  
  
    ls = cycle->listening.elts;  
    for (i = 0; i < cycle->listening.nelts; i++) {  
  
        c = ls[i].connection;  
  
        if (c == NULL || c->read->active) {  
            continue;  
        }  
        
        //添加事件：下文我们会以epoll模块为例详细分析该函数
        if (ngx_add_event(c->read, NGX_READ_EVENT, 0) == NGX_ERROR) {  
            return NGX_ERROR;  
        }  
    }  
  
    return NGX_OK;  
}  

static ngx_int_t ngx_disable_accept_events(ngx_cycle_t *cycle, ngx_uint_t all) {
    ngx_uint_t i;
    ngx_listening_t *ls;
    ngx_connection_t *c;  
  
    ls = cycle->listening.elts;  
    for (i = 0; i < cycle->listening.nelts; i++) {  
        ...
  
        //删除事件  
        if (ngx_del_event(c->read, NGX_READ_EVENT, NGX_DISABLE_EVENT) == NGX_ERROR) {  
            return NGX_ERROR;  
        }  
    }  
  
    return NGX_OK;  
}
```
该函数比较简单，拿到ngx_accept_mutex，则将监听socket加入到事件分发器（epoll）中；否则从事件分发器删除监听socket。接下来看一下ngx_event_process_posted函数：

```c
void ngx_event_process_posted(ngx_cycle_t *cycle, ngx_queue_t *posted) {
    ngx_queue_t *q;
    ngx_event_t *ev;  
  
    while (!ngx_queue_empty(posted)) {  
  
        q = ngx_queue_head(posted);  
        ev = ngx_queue_data(q, ngx_event_t, queue);    
        ngx_delete_posted_event(ev);  
  
        //事件回调函数  
        ev->handler(ev);  
    }  
}
```
该函数比较简单，就是循环处理ngx_posted_accept_events和ngx_posted_events队列中的相关事件。最后我们看一下事件处理核心函数ngx_process_events：这里以epoll为例，简单看一下ngx_epoll_process_events函数：

```c
//ngx_epoll_module.c
static ngx_int_t ngx_epoll_process_events(ngx_cycle_t *cycle, ngx_msec_t timer, ngx_uint_t flags) {
    int                events;
    uint32_t           revents;
    ngx_int_t          instance, i;
    ngx_uint_t         level;
    ngx_err_t          err;
    ngx_event_t       *rev, *wev;
    ngx_queue_t       *queue;
    ngx_connection_t  *c;
        
    //调用epoll_wait等待相关事件准备就绪
    events = epoll_wait(ep, event_list, (int) nevents, timer);

    err = (events == -1) ? ngx_errno : 0;

    if (flags & NGX_UPDATE_TIME || ngx_event_timer_alarm) {
        ngx_time_update();
    }
    ...
    
    //遍历epoll_wait返回的所有已准备就绪的事件，并处理这些事件
    for (i = 0; i < events; i++) {
        c = event_list[i].data.ptr;

        instance = (uintptr_t) c & 1;
        c = (ngx_connection_t *) ((uintptr_t) c & (uintptr_t) ~1);
        
        //获取连接上的读事件
        rev = c->read;
        //判断事件是否过期
        if (c->fd == -1 || rev->instance != instance) {
            continue;
        }
        
        revents = event_list[i].events;
        //EPOLLERR表示连接出错，EPOLLHUP表示收到RST报文
        if (revents & (EPOLLERR|EPOLLHUP)) {
            revents |= EPOLLIN|EPOLLOUT;
        }
        
        //连接上活跃的可读事件
        if ((revents & EPOLLIN) && rev->active) {
        
#if (NGX_HAVE_EPOLLRDHUP)
            //EPOLLRDHUP表示对端关闭了读取端
            if (revents & EPOLLRDHUP) {
                rev->pending_eof = 1;
            }

            rev->available = 1;
#endif

            rev->ready = 1;

            if (flags & NGX_POST_EVENTS) {
                //拿到ngx_accept_mutex，将accept事件放到ngx_posted_accept_events队列中，普通事件放到ngx_posted_events队列中
                queue = rev->accept ? &ngx_posted_accept_events : &ngx_posted_events;
                ngx_post_event(rev, queue);
            } else {
                rev->handler(rev);
            }
        }
        
        //获取连接上的写事件
        wev = c->write;        
        //连接上活跃的可写事件
        if ((revents & EPOLLOUT) && wev->active) {
            //写事件是否过期
            if (c->fd == -1 || wev->instance != instance) {
                continue;
            }

            wev->ready = 1;
            if (flags & NGX_POST_EVENTS) {
                //拿到ngx_accept_mutex，将普通事件放到ngx_posted_events队列中
                ngx_post_event(wev, &ngx_posted_events);
            } else {
                //否则直接调用handler回调函数处理该事件
                wev->handler(wev);
            }
        }
    }

    return NGX_OK;
}
```
