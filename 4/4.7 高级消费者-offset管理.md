## 4.7 高级消费者-offset管理

我们知道，Consumer抓取数据之前要先获取到该Partition的Offset，这样Fetcher才能知道要从Partition的哪个fetchOffset开始抓取数据。同时Consumer会定时地commitOffset。根据Offset信息保存在Zk还是Kafka上分为两种情况，这里以Kafka为例，简单分析一下该流程：
* 首先初始化GroupCoordinator的通信连接offsetsChannel，用于之后的fetchOffset和commitOffset
* Consumer抓取数据时首先通过offsetsChannel，发送OffsetFetchRequest，以获取offset
* Consumer会不停的commitOffset，即通过offsetsChannel，发送OffsetCommitRequest请求，保存offset

### 4.7.1 OffsetManager
前面说过，在创建ZookeeperConsumerConnector时会调用ensureOffsetManagerConnected方法建立到GroupCoordinator上的OffsetManager的通道，即OffsetChannel。
```scala
// Blocks until the offset manager is located and a channel is established to it.
private def ensureOffsetManagerConnected() {
    if (config.offsetsStorage == "kafka") {
        if (offsetsChannel == null || !offsetsChannel.isConnected)
            offsetsChannel = ClientUtils.channelToOffsetManager(config.groupId, zkUtils, ..)
    }
}
```
```scala
def channelToOffsetManager(group: String, zkUtils: ZkUtils, socketTimeoutMs: Int = 3000, retryBackOffMs: Int = 1000) = {
    //从/brokers/ids中寻找一个在线的Broker，然后和其建立连接
    var queryChannel = channelToAnyBroker(zkUtils)

    var offsetManagerChannelOpt: Option[BlockingChannel] = None
    //直到和coordinator建立通信连接为止
    while (offsetManagerChannelOpt.isEmpty) {
        var coordinatorOpt: Option[BrokerEndPoint] = None
        while (coordinatorOpt.isEmpty) {
            try {
                //通信连接断开，则重新连接
                if (!queryChannel.isConnected)
                    queryChannel = channelToAnyBroker(zkUtils)
                //发送GroupCoordinatorRequest
                queryChannel.send(GroupCoordinatorRequest(group))
                val response = queryChannel.receive()
                //接收ConsumerMatadataResponse
                val consumerMetadataResponse = GroupCoordinatorResponse.readFrom(response.payload())
                if (consumerMetadataResponse.error == Errors.NONE)
                    coordinatorOpt = consumerMetadataResponse.coordinatorOpt
                else {
                    Thread.sleep(retryBackOffMs)
                }
            } catch {
                ...
            }
        }

        val coordinator = coordinatorOpt.get
        if (coordinator.host == queryChannel.host && coordinator.port == queryChannel.port) {
            //如果coordinator和queryChannel相同，则直接返回queryChannel
            offsetManagerChannelOpt = Some(queryChannel)
        } else {
            //不同，则连接到目标coordinator，并断开当前queryChannel
            var offsetManagerChannel: BlockingChannel = null
            try {
                offsetManagerChannel = new BlockingChannel(coordinator.host, coordinator.port,
                    BlockingChannel.UseDefaultBufferSize,
                    BlockingChannel.UseDefaultBufferSize,
                    socketTimeoutMs)
                offsetManagerChannel.connect()
                offsetManagerChannelOpt = Some(offsetManagerChannel)
                queryChannel.disconnect()
            } catch {
                ...
            }
        }
    }

    offsetManagerChannelOpt.get
}    
```
简单分析一下该方法：
* 首先调用channelToAnyBroker方法，任意选取一个Broker和其建立连接queryChannel
* 然后通过queryChannel发送GroupCoordinatorRequest，并接收ConsumerMetadataResponse
* 解析该Response，获取coordinator的host和port信息，如果和当前queryChannel信息一致，说明GroupCoordinator就是该Broker，则直接返回该queryChannel；否则建立到该GroupCoordinator的连接，并断开当前queryChannel。

### 4.7.2 fetchOffset
前面我们说过，Consumer开始消费数据之前，必须首先fetchOffsets。这里分为从Zk或者Kafka上获取两种情况：Zk上则是读取/consumers/group/offsets/topic/partition目录下的数据，Kafka上则是通过offsetsChannel发送OffsetFetchRequest来获取，具体逻辑如下所示：
```scala
private def fetchOffsets(partitions: Seq[TopicAndPartition]) = {
    if (partitions.isEmpty)
        Some(OffsetFetchResponse(Map.empty))
    else if (config.offsetsStorage == "zookeeper") {
        //从zk上获取
        val offsets = partitions.map(fetchOffsetFromZooKeeper)
        Some(OffsetFetchResponse(immutable.Map(offsets: _*)))
    } else {
        //构造OffsetFetchRequest
        val offsetFetchRequest = OffsetFetchRequest(groupId = config.groupId, requestInfo = partitions, clientId = config.clientId)

        var offsetFetchResponseOpt: Option[OffsetFetchResponse] = None
        while (!isShuttingDown.get && !offsetFetchResponseOpt.isDefined) {
            offsetFetchResponseOpt = offsetsChannelLock synchronized {
                ensureOffsetManagerConnected()
                try {
                    //发送OffsetFetchRequest
                    offsetsChannel.send(offsetFetchRequest)
                    //读取OffsetFetchResponse
                    val offsetFetchResponse = OffsetFetchResponse.readFrom(offsetsChannel.receive().payload())

                    val (leaderChanged, loadInProgress) =
                        offsetFetchResponse.requestInfo.values.foldLeft(false, false) { case (folded, offsetMetadataAndError) =>
                            (folded._1 || (offsetMetadataAndError.error == Errors.NOT_COORDINATOR),
                                    folded._2 || (offsetMetadataAndError.error == Errors.COORDINATOR_LOAD_IN_PROGRESS))
                        }

                    if (leaderChanged) {
                        offsetsChannel.disconnect()
                        None // retry
                    }
                    else if (loadInProgress) {
                        debug("Could not fetch offsets (because offset cache is being loaded).")
                        None // retry
                    }
                    else {
                        if (config.dualCommitEnabled) {
                            // if dual-commit is enabled, then pick the max between offsets in zookeeper and kafka.
                            val kafkaOffsets = offsetFetchResponse.requestInfo
                            val mostRecentOffsets = kafkaOffsets.map { case (topicPartition, kafkaOffset) =>
                                val zkOffset = fetchOffsetFromZooKeeper(topicPartition)._2.offset
                                val mostRecentOffset = zkOffset.max(kafkaOffset.offset)
                                (topicPartition, OffsetMetadataAndError(mostRecentOffset, kafkaOffset.metadata, Errors.NONE))
                            }
                            Some(OffsetFetchResponse(mostRecentOffsets))
                        }
                        else
                            Some(offsetFetchResponse)
                    }
                } catch {
                    ...
                }
            }

            if (offsetFetchResponseOpt.isEmpty) {
                Thread.sleep(config.offsetsChannelBackoffMs)
            }
        }

        offsetFetchResponseOpt
    }
}
```

### 4.7.3 commitOffset
commitOffset时，会将当前Comsumer消费的offset提交到Zk或者Kafka中，提交到Zk时会更新/consumers/group/offsets/topic/partition目录下的数据，提交到Kafka则是利用offsetsChannel发送OffsetCommitRequest，具体实现如下所示：
```scala
def commitOffsets(isAutoCommit: Boolean) {
    val offsetsToCommit =
        immutable.Map(topicRegistry.values.flatMap { partitionTopicInfos =>
            partitionTopicInfos.values.map { info =>
                TopicAndPartition(info.topic, info.partitionId) -> OffsetAndMetadata(info.getConsumeOffset())
            }
        }.toSeq: _*)

    commitOffsets(offsetsToCommit, isAutoCommit)
}
def commitOffsets(offsetsToCommit: immutable.Map[TopicAndPartition, OffsetAndMetadata], isAutoCommit: Boolean) {
    //计算重试次数，由offsets.commit.max.retries决定，默认是5
    var retriesRemaining = 1 + (if (isAutoCommit) 0 else config.offsetsCommitMaxRetries)
    var done = false
    while (!done) {
        val committed = offsetsChannelLock synchronized {
            // committed when we receive either no error codes or only MetadataTooLarge errors
            //提取需要提交的offset（topic、partition和offset）
            if (offsetsToCommit.size > 0) {
                if (config.offsetsStorage == "zookeeper") {
                    //提交Zookeeper上
                    offsetsToCommit.foreach { case (topicAndPartition, offsetAndMetadata) =>
                        commitOffsetToZooKeeper(topicAndPartition, offsetAndMetadata.offset)
                    }
                    true
                } else {
                    //提交到Kafka，组装OffsetCommitRequest
                    val offsetCommitRequest = OffsetCommitRequest(config.groupId, offsetsToCommit, clientId = config.clientId)
                    ensureOffsetManagerConnected()
                    try {
                        kafkaCommitMeter.mark(offsetsToCommit.size)
                        //发送OffsetCommitRequest，并读取Response
                        offsetsChannel.send(offsetCommitRequest)
                        val offsetCommitResponse = OffsetCommitResponse.readFrom(offsetsChannel.receive().payload())

                        val (commitFailed, retryableIfFailed, shouldRefreshCoordinator, errorCount) = {
                            offsetCommitResponse.commitStatus.foldLeft(false, false, false, 0) { case (folded, (topicPartition, error)) =>

                                if (error == Errors.NONE && config.dualCommitEnabled) {
                                    val offset = offsetsToCommit(topicPartition).offset
                                    commitOffsetToZooKeeper(topicPartition, offset)
                                }

                                (folded._1 || // update commitFailed
                                        error != Errors.NONE,

                                        folded._2 || // update retryableIfFailed - (only metadata too large is not retryable)
                                                (error != Errors.NONE && error != Errors.OFFSET_METADATA_TOO_LARGE),

                                        folded._3 || // update shouldRefreshCoordinator
                                                error == Errors.NOT_COORDINATOR ||
                                                error == Errors.COORDINATOR_NOT_AVAILABLE,

                                        // update error count
                                        folded._4 + (if (error != Errors.NONE) 1 else 0))
                            }
                        }

                        if (shouldRefreshCoordinator) {
                            offsetsChannel.disconnect()
                        }

                        if (commitFailed && retryableIfFailed)
                            false
                        else
                            true
                    } catch {
                        ...
                    }
                }
            } else {
                true
            }
        }

        //判断是否完成
        done = {
            retriesRemaining -= 1
            retriesRemaining == 0 || committed
        }

        //未完成，则休眠offsets.channel.backoff.ms毫秒
        if (!done) {
            Thread.sleep(config.offsetsChannelBackoffMs)
        }
    }
}
```
